
# Lab 1: Collaborative Perception for Autonomous Vehicles

## Overview:  
The objective of this exercise was to experiment with point clouds generated by different actors in the environment, simulating the shared perception from V2V and V2X communications.  
## Task 1:  
The first task was about developing a function called `box_to_corner()` to convert the format of the bounding boxes to a list of points (corners coordinates) and a function `get_boxes_in_actor_frame()` to transform the boxes from the sensor frame to the actor frame  
This allowed us to obtain a point cloud plus bounding boxes of the first vehicle (referred to as _ego_ vehicle)
![Screenshot 2024-11-29 181742](https://github.com/user-attachments/assets/17bbf3c0-4e5f-44dd-a605-6a47044a6153)

## Task 2:  
After developing the necessary base function in task 1, it was time to aggregate the point clouds coming from different actors in the environment. To do so it was necessary to take all the actor's point clouds and bounding boxes in their own local frame and project them into the _ego vehicle_ frame. To do so it was necessary to complete the implementation of the two functions `get_available_point_clouds` and `get_available_boxes_in_ego_frame` thus providing to the _ego vehicle_ an extended perception of the environment also containing all the perceived actors, labeled by class.  

![Screenshot 2024-11-29 181817](https://github.com/user-attachments/assets/e5fe76dd-64f5-4ec4-b6c0-b9389cf1ddcd)

## Task 3:
This task involved producing a bird-eye-view image of the environment occupancy grid, a slimmer approach to conveying information about the presence of actors in the proximities of the _ego vehicle_. To complete the task it was necessary to implement the `box_to_pixels` and `points_to_pixels` functions; the former was used to convert the bounding boxes of the actors into 2D representation for the BEV image, while the latter was used to convert the points belonging to the ground into pixels for the BEV image.  
The last function to complete was `filter_points` which was used to filter out everything but the ground points from the point cloud.  

![Screenshot 2024-11-29 181830](https://github.com/user-attachments/assets/652de7e0-784d-4ac4-9feb-ff27a6cbf809)

![Screenshot 2024-11-29 181845](https://github.com/user-attachments/assets/6c784ce4-1b52-44a0-bf0a-e9cf08823194)

## Task 4:
The last task was about visualization, this section contains the code to produce a user interface that could retrieve BEV images containing only specific classes of objects (car, truck, pedestrian, motorcycle)

![car_BEV](https://github.com/user-attachments/assets/d033a510-becb-4796-8b81-c4750e5f85b3)
